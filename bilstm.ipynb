{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealModel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aXLlRCWGlH3A"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjLJc0RXwZl0",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains the main model for the NLP Project. It contains an LSTM model as specified in our report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCUnQlL_kvOS",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD2x46rzvZrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch import autograd\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchtext import data\n",
        "import re\n",
        "!pip install sentistrength\n",
        "from sentistrength import PySentiStr\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "from typing import List, Tuple\n",
        "from itertools import islice\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NYdc40pv-1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the LIAR-PLUS training data\n",
        "\n",
        "liar_id = \"1znUzJPalC4z9MPmfovFLqp8S0x608Kfx\"\n",
        "downloaded = drive.CreateFile({'id':liar_id}) \n",
        "downloaded.GetContentFile('train2.tsv') \n",
        "train_data=pd.read_csv('train2.tsv',delimiter='\\t',encoding='utf-8', header = None, index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enT5L3OkeVLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the LIAR-PLUS dev data\n",
        "\n",
        "liar_id = \"1OBONJoZ05il1_xHlvZVWpsZg7GHt5xqs\"\n",
        "downloaded = drive.CreateFile({'id':liar_id}) \n",
        "downloaded.GetContentFile('val2.tsv') \n",
        "val_data=pd.read_csv('val2.tsv',delimiter='\\t',encoding='utf-8', header = None, index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hImqlQywYy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the LIAR-PLUS test data\n",
        "\n",
        "liar_test_id = \"1ywwBKp9b-lowXy-wfYcIZmhuVHW5xDAv\"\n",
        "downloaded = drive.CreateFile({'id':liar_test_id}) \n",
        "downloaded.GetContentFile('test2.tsv') \n",
        "test_data=pd.read_csv('test2.tsv',delimiter='\\t',encoding='utf-8', header = None, index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVBfU1eG0qIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the smaller GloVe embeddings \n",
        "\n",
        "glove_data_id = \"1wvEbRqdbwPmgfdJpxnKsk4xHQ73kko5s\"\n",
        "glove_downloaded = drive.CreateFile({'id': glove_data_id})\n",
        "glove_downloaded.GetContentFile(\"glove.6B.50d.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ackBX650sUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process GloVe embeddings\n",
        "# embeddings_dict is dictionary where each key is a word and each value is the vector embedding \n",
        "# words is list of words; vectorsglove is list of vectors\n",
        "# word2idx maps words to id; glove maps words to vector\n",
        "\n",
        "idx = 0\n",
        "words =[]\n",
        "word2idx = {}\n",
        "embeddings_dict = {}\n",
        "vectorsglove = []\n",
        "with open(\"glove.6B.50d.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector\n",
        "        vectorsglove.append(vector)\n",
        "\n",
        "glove = {w: vectorsglove[word2idx[w]] for w in words}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-CeNTye6kyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get vocab\n",
        "\n",
        "def get_vocab(data):\n",
        "  # Returns list of vocab\n",
        "  statements = data[3]\n",
        "  justifications = data[15]\n",
        "\n",
        "  vocab = []\n",
        "  for i in range(len(statements)):\n",
        "    # Tokenize statement: remove punctuation and split on whitespace\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',statements[i])\n",
        "    words = re.split(r' ',sample.lower())\n",
        "\n",
        "    # Tokenize justification\n",
        "    if justifications[i] != justifications[i]: continue     # If justification is empty\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',justifications[i])\n",
        "    justs = re.split(r' ',sample.lower())\n",
        "\n",
        "    both = words + justs\n",
        "\n",
        "    # Add new words to vocab\n",
        "    vectors = []\n",
        "    for word in both:\n",
        "      if word not in vocab:\n",
        "        vocab.append(word)\n",
        "    \n",
        "  return vocab\n",
        "\n",
        "# Get vocab of train data\n",
        "train_vocab = get_vocab(train_data) # 10156 samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJNO99nF7UX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get pretrained weights/embeddings\n",
        "# weights maps id to vector\n",
        "# If word isn't in GloVe, then initialize as random vector\n",
        "\n",
        "weights = np.zeros((len(train_vocab),50))\n",
        "\n",
        "for i, word in enumerate(train_vocab):\n",
        "  try:\n",
        "    weights[i] = glove[word]\n",
        "  except KeyError:\n",
        "    weights[i] = np.random.normal(scale=.6,size=(50, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYdxbC75CHlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dictionaries to store word to index mappings and vice versa\n",
        "\n",
        "word2id = {o:i for i,o in enumerate(train_vocab)}\n",
        "id2word = {i:o for i,o in enumerate(train_vocab)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXLlRCWGlH3A",
        "colab_type": "text"
      },
      "source": [
        "# Process Inputs (These cells were already ran to preocess the data, no need to run again)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDtWATotJczI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is EmoLex \n",
        "'''\n",
        "emolex_id = \"13M2WhB_etUUYUmdYDR0eQ3nbxbfJYhnG\"\n",
        "emolex_downloaded = drive.CreateFile({'id': emolex_id})\n",
        "emolex_downloaded.GetContentFile(\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\")\n",
        "''';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNlJTOFeBAq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process EmoLex\n",
        "# Dictionary where each value is a word and each key is a 8-dim vector\n",
        "'''\n",
        "emo_dict = {}\n",
        "with open(\"NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\", 'r') as f:\n",
        "    vector = []\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        if len(values) == 0: continue\n",
        "        word = values[0]\n",
        "        vector.append(values[2])\n",
        "        if len(vector) == 10:\n",
        "          emo_dict[word] = vector\n",
        "          vector = []\n",
        "''';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXeBIKeITR1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hedge lexicon (only has one-word hedges)\n",
        "\n",
        "hedges = ['largely', 'generally','often','rarely','sometimes','frequently','occasionally','seldom','usually','most','several','some',\n",
        "         'almost','practically','apparently','virtually','basically','approximately','roughly','somewhat','somehow','partially',\n",
        "         'actually','like','something','someone','somebody','somewhere','think','thinks','thought','believe','believed','believes',\n",
        "         'consider','considers','considered','assume','assumes','assumed','understand','understands','understood','find','found',\n",
        "         'finds','appear','appears','appeared','seem','seems','seemed','suppose','supposes','supposed','guess','guesses','guessed',\n",
        "         'estimate','estimates','estimated','speculate','speculates','speculated','suggest','suggests','suggested','may','could',\n",
        "         'should','might','surely','probably','likely','maybe','perhaps','unsure','probable','unlikely','possibly','possible',\n",
        "         'read','say','says','necessarily','much','bunch','couple','few','little','really','about','around','can','effectively',\n",
        "         'evidently','fairly','hopefully','mainly','mostly','overall','presumably','pretty','quite','rather','supposedly','tend',\n",
        "         'doubt','indicate','will','must','would','certainly','definitely','clearly','conceivably','certain','definite','clear',\n",
        "         'assumption','possibility','probability','many','improbable','always','rare','doubtful','suggestive','diagnostic',\n",
        "         'inconclusive','apparent','alleged','allege','presumable']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEVLbXoLY85w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is SentiStrength stuff\n",
        "'''\n",
        "sentijar_id = \"1JeskOiyOdVUZ7rjhFKajOp-52OUcn64P\"\n",
        "senti_downloaded = drive.CreateFile({'id':sentijar_id}) \n",
        "senti_downloaded.GetContentFile('SentiStrength.jar') \n",
        "\n",
        "senti = PySentiStr()\n",
        "senti.setSentiStrengthPath(\"/content/SentiStrength.jar\")    \n",
        "senti.setSentiStrengthLanguageFolderPath(\"/content/SentStrength_Data/\")   # Have to reupload this folder\n",
        "''';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI8xHaUEzeCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process input data\n",
        "'''\n",
        "def format_input(data):\n",
        "  # Returns 3 np arrays: statement embeddings, justification embeddings, features (semantic strength + pos/neg, emotion, \n",
        "  # amount of hedging, prior history x 5)\n",
        "  statements = data[3]\n",
        "  justifications = data[15]\n",
        "  prior1 = data[9]; prior2 = data[10]; prior3 = data[11]; prior4 = data[12]; prior5 = data[13]\n",
        "\n",
        "  sts = []\n",
        "  jsts = []\n",
        "  feats = []\n",
        "\n",
        "  for i in range(len(statements)):\n",
        "    # Tokenize statement: remove punctuation and split on whitespace\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',statements[i])\n",
        "    words = re.split(r' ',sample.lower())\n",
        "\n",
        "    # Tokenize justification\n",
        "    if justifications[i] != justifications[i]: continue     # If justification is empty\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',justifications[i])\n",
        "    justs = re.split(r' ',sample.lower())\n",
        "\n",
        "    # GloVe embedding for each word in statement\n",
        "    vectors = []\n",
        "    for word in words:\n",
        "      if word in embeddings_dict: \n",
        "        vectors.append(embeddings_dict[word])\n",
        "    sts.append(vectors)\n",
        "    \n",
        "    # GloVe embedding for each word in justification\n",
        "    vectors = []\n",
        "    for word in justs:\n",
        "      if word in embeddings_dict: \n",
        "        vectors.append(embeddings_dict[word])\n",
        "    jsts.append(vectors)\n",
        "    \n",
        "    ifeats = []\n",
        "    # Sentiment strength for the statement\n",
        "    ifeats.extend(senti.getSentiment(statements[i]))\n",
        "\n",
        "    # Sum of 8-dim emotion vectors for each word in statement\n",
        "    emo = []\n",
        "    for word in words:\n",
        "      if word in emo_dict: emo.append([float(x) for x in emo_dict[word]])\n",
        "    emo = np.array(emo)\n",
        "    if len(emo) > 0:\n",
        "      ifeats.extend(np.mean(emo,axis=0))\n",
        "    else:\n",
        "      ifeats.extend([0,0,0,0,0,0,0,0])\n",
        "\n",
        "    # Hedging\n",
        "    hedge = 0.0\n",
        "    for word in words:\n",
        "      if word in hedges: hedge += 1.0\n",
        "    ifeats.append(hedge)\n",
        "\n",
        "    # Prior history 5-dim vector\n",
        "    ifeats.extend(np.array([float(prior1[i]),float(prior2[i]),float(prior3[i]),float(prior4[i]),float(prior5[i])]))\n",
        "\n",
        "    feats.append(np.array(ifeats))\n",
        "    \n",
        "  return np.array(sts), np.array(jsts), np.array(feats)\n",
        "\n",
        "# Format train and test data\n",
        "#train_st, train_jst, train = format_input(train_data) # 10156 samples\n",
        "#dev_st, dev_jst, dev = format_input(val_data)         # 1280 samples\n",
        "#test_st, test_jst, test = format_input(test_data)     # 1258 samples\n",
        "''';"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmbqSct0uvGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell was already ran so no need to run again.\n",
        "# Save processed input to (Tessa's) drive\n",
        "\n",
        "#f = open(\"/content/drive/My Drive/dev_st.csv\",\"w\")\n",
        "#for statement in dev_st:\n",
        "#  f.write('\\n')\n",
        "#  for word in statement:\n",
        "#    w = \"\"\n",
        "#    for each in word:\n",
        "#      w += str(each) + \",\"\n",
        "#    f.write(w)\n",
        "#f.close()\n",
        "\n",
        "#f = open(\"/content/drive/My Drive/dev.csv\",\"w\")\n",
        "#for statement in dev:\n",
        "#  f.write('\\n')\n",
        "#  w = \"\"\n",
        "#  for each in statement:\n",
        "#    w += str(each) + \",\"\n",
        "#  f.write(w)\n",
        "#f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iJ8sBPzutNm",
        "colab_type": "text"
      },
      "source": [
        "# Import Processed Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L41GBAWuwn3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load processed input from drive\n",
        "\n",
        "def load_feats_drive(fname):\n",
        "  new_arr = []\n",
        "  f = open(fname,\"r\")\n",
        "  for statement in f:\n",
        "    st = []\n",
        "    if len(statement) == 1: continue\n",
        "    parts = statement.split(',')[:-1]\n",
        "    for each in parts:\n",
        "      if float(each) != float(each): st.append(0.0)\n",
        "      else: st.append(float(each))\n",
        "    if len(st) != 17: \n",
        "      st.insert(0,0.0)\n",
        "      st.insert(0,0.0)\n",
        "    new_arr.append(st)\n",
        "  f.close()\n",
        "  return new_arr\n",
        "\n",
        "train_id = \"1-hxnB0ngKi4Ti1WgDOAmwrnwLtEOqObe\"\n",
        "downloaded = drive.CreateFile({'id':train_id}) \n",
        "downloaded.GetContentFile('train.csv') \n",
        "dev_id = \"1-6Os5O0E7coeK5vf8OT1Ga5Jqj61UAk2\"\n",
        "downloaded = drive.CreateFile({'id':dev_id}) \n",
        "downloaded.GetContentFile('dev.csv') \n",
        "test_id = \"1-dK6qgdFo4IcmALUewlHCjAYTtIRAYG0\"\n",
        "downloaded = drive.CreateFile({'id':test_id}) \n",
        "downloaded.GetContentFile('test.csv') \n",
        "\n",
        "train_u = load_feats_drive(\"train.csv\") # William thinks 'u' means unnormalized. \n",
        "dev_u =   load_feats_drive(\"dev.csv\")\n",
        "test_u =  load_feats_drive(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqNDSEE7CMRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale/normalize the feature vectors\n",
        "\n",
        "train = np.array([np.array([float(i)/sum(x) if sum(x) != 0 else 0.0 for i in x]) for x in train_u]) \n",
        "dev   = np.array([np.array([float(i)/sum(x) if sum(x) != 0 else 0.0 for i in x]) for x in dev_u])\n",
        "test  = np.array([np.array([float(i)/sum(x) if sum(x) != 0 else 0.0 for i in x]) for x in test_u])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLDbitQBmk5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list of hedge words\n",
        "# amount of hedging of a sample is measured by the number of hedge words used in the statement\n",
        "hedging = ['may', 'might', 'can', 'could','would', 'should', 'seem', 'appear', 'believe', 'assume', 'suggest', 'claim','possibility'\n",
        "           'estimate', 'tend', 'think', 'argue', 'indicate', 'propose', 'speculate', 'possible', 'probable','likely','assumption',\n",
        "           'estimate', 'suggestion', 'perhaps', 'possibly','probably','practically', 'likely', 'presumably','virtually', 'apparently',\n",
        "           'approximately','roughly', 'about', 'often','occasionally','generally', 'usually','somewhat', 'somehow','a lot of','believe', \n",
        "           'to our knowledge', 'it is our', 'view that', 'we feel that']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ8SBLWjrguE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get ground truth labels\n",
        "\n",
        "def format_ans(data):\n",
        "  answers = []\n",
        "  lab = data[2]\n",
        "  justs = data[15]\n",
        "  for each in range(len(data)):\n",
        "    if justs[each] != justs[each]: continue\n",
        "    if   lab[each] == 'pants-fire':  answers.append(0)\n",
        "    elif lab[each] == 'false':       answers.append(1)\n",
        "    elif lab[each] == 'barely-true': answers.append(2)\n",
        "    elif lab[each] == 'half-true':   answers.append(3)\n",
        "    elif lab[each] == 'mostly-true': answers.append(4)\n",
        "    elif lab[each] == 'true':        answers.append(5)\n",
        "    else: print(\"The label inputted is not a known label.\")\n",
        "  return np.array(answers)\n",
        "\n",
        "train_labels = format_ans(train_data)\n",
        "dev_labels   = format_ans(val_data)\n",
        "test_labels  = format_ans(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_uDNhLr7IY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get sentences\n",
        "\n",
        "def get_words(data):\n",
        "  # Returns list of lists, where each inner list is all words in one statement and justification\n",
        "  statements = data[3]\n",
        "  justifications = data[15]\n",
        "  stjsts = []\n",
        "\n",
        "  for i in range(len(statements)):\n",
        "    # Tokenize statement: remove punctuation and split on whitespace\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',statements[i])\n",
        "    words = re.split(r' ',sample.lower())\n",
        "\n",
        "    if justifications[i] != justifications[i]: continue     # If justification is empty\n",
        "    sample = re.sub(r'[^\\w\\s]',' ',justifications[i])\n",
        "    justs = re.split(r' ',sample.lower())\n",
        "\n",
        "    # put together\n",
        "    stjsts.append(words + justs)\n",
        "    ##stjsts.append(words)\n",
        "  return stjsts\n",
        "\n",
        "train_words = get_words(train_data)\n",
        "dev_words = get_words(val_data)\n",
        "test_words = get_words(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvrDflTDCffC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert sentences to id numbers and pad to 200 words\n",
        "\n",
        "def word_to_id(sents):\n",
        "  new_sents = np.zeros((len(sents),200),dtype=int)\n",
        "  for i,sentence in enumerate(sents):\n",
        "    if len(sentence) != 0:\n",
        "      new_sents[i, -len(sentence):] = np.array([word2id[word] if word in word2id else 0 for word in sentence])[:200]\n",
        "  return new_sents\n",
        "\n",
        "train_w = word_to_id(train_words)\n",
        "dev_w = word_to_id(dev_words)\n",
        "test_w = word_to_id(test_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAT5gzFutBs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data is [words[][], features[][], labels[]]\n",
        "# words is an array of arrays of ints (representing words)\n",
        "# features is array of arrays of floats (representing feats)\n",
        "# labels is array of ints\n",
        "\n",
        "train_f = [torch.from_numpy(train_w).cuda(), torch.from_numpy(train).cuda(), torch.from_numpy(train_labels).cuda()]\n",
        "dev_f   = [torch.from_numpy(dev_w).cuda(),   torch.from_numpy(dev).cuda(),   torch.from_numpy(dev_labels).cuda()]\n",
        "test_f  = [torch.from_numpy(test_w).cuda(),  torch.from_numpy(test).cuda(),  torch.from_numpy(test_labels).cuda()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJtek0eqqyIS",
        "colab_type": "text"
      },
      "source": [
        "# Define Models and Train/Test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s0SaDW3nQ3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define our BiLSTM class\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, batch_size, use_gpu=True, dropout=0.5):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = use_gpu\n",
        "        self.dropout = dropout\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embeddings.load_state_dict({'weight': torch.from_numpy(weights)})\n",
        "        self.embeddings.weight.requires_grad = False\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=True)\n",
        "        self.hidden2label = nn.Linear(hidden_dim*2+17, label_size)\n",
        "        #self.hidden2label = nn.Linear(hidden_dim*2, label_size)###\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # First is the hidden h\n",
        "        # Second is the cell c\n",
        "        if self.use_gpu:\n",
        "            return (torch.zeros((2, self.batch_size, self.hidden_dim), requires_grad=True).cuda(),\n",
        "                    torch.zeros((2, self.batch_size, self.hidden_dim), requires_grad=True).cuda())\n",
        "        else:\n",
        "            return (torch.zeros((2, self.batch_size, self.hidden_dim), requires_grad=True),\n",
        "                    torch.zeros((2, self.batch_size, self.hidden_dim), requires_grad=True))\n",
        "\n",
        "    def forward(self, batch, features):\n",
        "        x = self.embeddings(batch).view(200, len(batch), -1)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        concat = torch.cat((lstm_out[-1].type(torch.FloatTensor).cuda(),features.type(torch.FloatTensor).cuda()),1)\n",
        "        y = self.hidden2label(concat)  \n",
        "        #y = self.hidden2label(lstm_out[-1].type(torch.FloatTensor).cuda()) ###\n",
        "        probs = F.log_softmax(y, 1) \n",
        "        return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNCCXtEIZTZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training and testing functions\n",
        "\n",
        "def get_accuracy(truth, pred):  \n",
        "    # Truth and pred are arrays of values; returns percentage correct\n",
        "    correct = 0\n",
        "    bi = 0\n",
        "    for i in range(len(truth)):\n",
        "        if truth[i] == pred[i]: correct += 1.0\n",
        "        if (truth[i] == 0 or truth[i] == 1 or truth[i] == 2) and (pred[i] == 0 or pred[i] == 1 or pred[i] == 2): bi += 1.0\n",
        "        elif (truth[i] == 3 or truth[i] == 4 or truth[i] == 5) and (pred[i] == 3 or pred[i] == 4 or pred[i] == 5): bi += 1.0\n",
        "    return correct/len(truth), bi/len(truth)\n",
        "\n",
        "def get_f1(truth, pred):\n",
        "  tp = [0,0,0,0,0,0]\n",
        "  fp = [0,0,0,0,0,0]\n",
        "  fn = [0,0,0,0,0,0]\n",
        "  b_tp = 0\n",
        "  b_fp = 0\n",
        "  b_fn = 0\n",
        "  for i in range(len(truth)):\n",
        "    for each in range(6):\n",
        "      if (truth[i] == each and pred[i] == each): tp[each] += 1.0\n",
        "      if (truth[i] == each and pred[i] != each): fp[each] += 1.0\n",
        "      if (truth[i] != each and pred[i] == each): fn[each] += 1.0\n",
        "    if (truth[i] == 0 or truth[i] == 1 or truth[i] == 2) and (pred[i] == 0 or pred[i] == 1 or pred[i] == 2): b_tp += 1.0\n",
        "    if (truth[i] == 0 or truth[i] == 1 or truth[i] == 2) and (pred[i] == 3 or pred[i] == 4 or pred[i] == 5): b_fp += 1.0\n",
        "    if (truth[i] == 3 or truth[i] == 4 or truth[i] == 5) and (pred[i] == 0 or pred[i] == 1 or pred[i] == 2): b_fn += 1.0\n",
        "  \n",
        "  r = [tp[x]/(tp[x]+fn[x]) if (tp[x]+fn[x] != 0) else 0.0 for x in range(6)]\n",
        "  p = [tp[x]/(tp[x]+fp[x]) if (tp[x]+fp[x] != 0) else 0.0 for x in range(6)]\n",
        "  f1 = [2*(p[x]*r[x])/(p[x]+r[x]) if (p[x]+r[x] != 0) else 0.0 for x in range(6)]\n",
        "  f1 = sum(f1)/6.0\n",
        "\n",
        "  br = b_tp/(b_tp+b_fn) if (b_tp+b_fn != 0) else 0.0\n",
        "  bp = b_tp/(b_tp+b_fp) if (b_tp+b_fp != 0) else 0.0\n",
        "  bf1 = 2*(bp*br)/(bp+br) if (bp+br != 0) else 0.0\n",
        "\n",
        "  return f1, bf1\n",
        "\n",
        "def evaluate(model, batches, data, loss_function, optimizer, e):\n",
        "    # (model: nn.Module, batches:List[Tuple[int, int]], data, loss_function, optimizer, evaluate:bool)\n",
        "    if e: model.eval()\n",
        "    else: model.train()\n",
        "    avg_loss = 0.0\n",
        "    batches = batches.copy()\n",
        "    #np.random.shuffle(batches)\n",
        "    truth_res = []\n",
        "    pred_res = []\n",
        "    for batch_i,(start,end) in enumerate(batches):\n",
        "        model.hidden = model.init_hidden()\n",
        "        stjst, feats, labels = data[0][start:end], data[1][start:end], data[2][start:end]\n",
        "        truth_res.extend(labels)\n",
        "        pred = model(stjst, feats)\n",
        "        pred_label = pred.max(1)[1]\n",
        "        pred_res.extend([x for x in pred_label])\n",
        "        if not e: \n",
        "            model.zero_grad()\n",
        "        loss = loss_function(pred, labels)\n",
        "        avg_loss += loss.item()\n",
        "        if not e:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    avg_loss /= len(batches)\n",
        "    acc, acc2 = get_accuracy(truth_res, pred_res)\n",
        "    if e: \n",
        "      f1, bf1 = get_f1(truth_res, pred_res)\n",
        "      return avg_loss, acc, acc2, f1, bf1\n",
        "    return avg_loss, acc, acc2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK5UGSHTq571",
        "colab_type": "text"
      },
      "source": [
        "# Train and Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luvBE1ROxKoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement model\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "batchsize = 64\n",
        "bilstm = BiLSTM(embedding_dim=50, hidden_dim=32, vocab_size=len(train_vocab), label_size=6, use_gpu=True, batch_size=batchsize)\n",
        "bilstm.to(device)\n",
        "\n",
        "# Train and test\n",
        "print('Model:')\n",
        "best_model = bilstm\n",
        "optimizer = optim.Adam(bilstm.parameters(), lr=0.01)\n",
        "loss_function = nn.NLLLoss()\n",
        "epochs = 10\n",
        "best_dev_acc = 0.0\n",
        "# Batches\n",
        "train_iter = [(start,start+batchsize) for start in range(0,10156,batchsize)]\n",
        "dev_iter =   [(start,start+batchsize) for start in range(0,1280,batchsize)]\n",
        "test_iter =  [(start,start+batchsize) for start in range(0,1258,batchsize)]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_loss, acc, acc2 = evaluate(bilstm, train_iter[:-1], train_f, loss_function, optimizer, e=False)\n",
        "    print('Train: loss %.2f acc %.1f' % (avg_loss, acc*100))\n",
        "    dev_avg_loss, dev_acc, dev_acc2, f1, bf1 = evaluate(bilstm, dev_iter, dev_f, loss_function, optimizer, e=True)\n",
        "    print('Dev: loss %.2f acc %.1f' % (dev_avg_loss, dev_acc*100))\n",
        "    if dev_acc > best_dev_acc:\n",
        "        best_dev_acc = dev_acc\n",
        "        best_model = bilstm\n",
        "        #torch.save(best_model.state_dict(), '/content/bilstm_best_model.pth')\n",
        "        # Evaluate on test with the best dev performance model\n",
        "        #test_avg_loss, test_acc = evaluate(best_model, test_iter[:-1], test_f, loss_function, optimizer, e=True)\n",
        "        #print('Test: loss %.2f acc %.1f' % (test_avg_loss, test_acc*100))\n",
        "test_avg_loss, test_acc, test_acc2, f1, bf1 = evaluate(best_model, test_iter[:-1], test_f, loss_function, optimizer, e=True)\n",
        "print('Final Test: loss %.2f acc %.2f 2-way acc %.2f f1 %.2f 2-way f1 %.2f' % (test_avg_loss, test_acc*100, test_acc2*100, f1, bf1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}